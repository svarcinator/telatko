{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spot\n",
    "import os\n",
    "import re\n",
    "from ltlcross_runner import LtlcrossRunner, ResultsAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "    'ltl2tgba_det': 'ltl2tgba -D -G %f > %O ',\n",
    "    'ltl3tela_det': '/home/xschwar3/ltl3tela-master/ltl3tela  -D1 -f %f > %O',\n",
    "    'ltl2tgba': 'ltl2tgba %f > %O ',\n",
    "    'ltl3tela': '/home/xschwar3/ltl3tela-master/ltl3tela -f %f > %O',\n",
    "    'delag': '/home/xschwar3/owl/bin/owl ltl2dela -f %f > %O',\n",
    "    'rabinizer4': '/home/xschwar3/owl/bin/owl ltl2dgra -f %f > %O',\n",
    "}\n",
    "tools_order = ['delag', 'rabinizer4', 'ltl2tgba', 'ltl3tela', 'ltl3tela_det']\n",
    "telatko = '/home/xschwar3/telatko/telatko.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_ltl = 'patterns.ltl'\n",
    "patterns_aut = 'patterns.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    patterns_ltl = 'test.ltl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_ltl = True\n",
    "rerun_aut = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcr = LtlcrossRunner(tools, formulas = [patterns_ltl], res_filename = patterns_aut)\n",
    "if rerun_ltl:\n",
    "    lcr.run_ltlcross(automata = True, timeout = '60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = ResultsAnalyzer(patterns_aut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.parse_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltlf_translated = {}\n",
    "\n",
    "for tool in tools_order:\n",
    "    fs = ra.values.filter(items = [('acc', tool)]).dropna()\n",
    "    \n",
    "    ltlf_translated[tool] = len(fs[fs[('acc', tool)] > 1])\n",
    "    \n",
    "    fd = open('patterns-' + tool + '.hoa', 'w')\n",
    "    for (ix, _), _ in fs.iterrows():\n",
    "        fd.write(ra.aut_for_id(ix, tool).to_str() + '\\n')\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.environ['SPOT_TMPDIR'] = '/home/xschwar3/telatko/concur_response_experiments/pattern-aut/autcross'\n",
    "os.environ['SPOT_TMPKEEP'] = '1'\n",
    "\n",
    "def run_autcross(tool):\n",
    "    !autcross --no-checks --csv=patterns-telatko-{tool}.csv -F patterns-{tool}.hoa 'autfilt %H > %O'   '{telatko} -F %H -T 30 -L 3 -I -G -O %O' 'autfilt %H > %O --simplify-acceptance' 'autfilt %H > %O --small' > autcross/{tool}.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Original', 'Multilevel', 'Autfilt -- simpl-acc', 'Autfilt small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_aut:\n",
    "    run_autcross('delag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_aut:\n",
    "    run_autcross('rabinizer4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_aut:\n",
    "    run_autcross('ltl2tgba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_aut:\n",
    "    run_autcross('ltl3tela')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_aut:\n",
    "    run_autcross('ltl3tela_det')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_aut:\n",
    "    run_autcross('ltl2tgba_det')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delag\n",
      "     Original  Multilevel  Autfilt -- simpl-acc  Autfilt small\n",
      "9           2           2                     2              2\n",
      "10          3           3                     3              3\n",
      "11          4           4                     4              4\n",
      "36          3           0                     3              1\n",
      "44          2           1                     1              1\n",
      "..        ...         ...                   ...            ...\n",
      "318         6           6                     6              6\n",
      "319         8           8                     8              8\n",
      "320         3           2                     2              2\n",
      "321         2           1                     1              1\n",
      "322         3           2                     2              2\n",
      "\n",
      "[129 rows x 4 columns]\n",
      "rabinizer4\n",
      "     Original  Multilevel  Autfilt -- simpl-acc  Autfilt small\n",
      "0           2           1                     1              1\n",
      "1           2           1                     1              1\n",
      "2           2           1                     1              1\n",
      "3           2           1                     1              1\n",
      "8           2           1                     1              1\n",
      "..        ...         ...                   ...            ...\n",
      "331         2           1                     1              1\n",
      "332         2           1                     1              1\n",
      "333         2           1                     1              1\n",
      "334         2           1                     1              1\n",
      "335         2           1                     1              1\n",
      "\n",
      "[234 rows x 4 columns]\n",
      "ltl2tgba\n",
      "     Original  Multilevel  Autfilt -- simpl-acc  Autfilt small\n",
      "9           2           2                     2              2\n",
      "10          3           3                     3              3\n",
      "11          4           4                     4              4\n",
      "65          2           2                     2              2\n",
      "66          2           2                     2              2\n",
      "..        ...         ...                   ...            ...\n",
      "323         3           3                     3              3\n",
      "324         4           4                     4              4\n",
      "340         2           1                     2              2\n",
      "341         3           1                     3              3\n",
      "342         4           4                     4              4\n",
      "\n",
      "[70 rows x 4 columns]\n",
      "ltl3tela\n",
      "     Original  Multilevel  Autfilt -- simpl-acc  Autfilt small\n",
      "9           2           2                     2              2\n",
      "10          3           3                     3              3\n",
      "11          4           4                     4              4\n",
      "65          2           2                     2              2\n",
      "66          2           2                     2              2\n",
      "..        ...         ...                   ...            ...\n",
      "307         2           2                     2              2\n",
      "309         2           2                     2              2\n",
      "322         2           1                     2              2\n",
      "323         3           1                     3              3\n",
      "324         4           4                     4              4\n",
      "\n",
      "[91 rows x 4 columns]\n",
      "ltl3tela_det\n",
      "     Original  Multilevel  Autfilt -- simpl-acc  Autfilt small\n",
      "9           2           2                     2              2\n",
      "10          3           3                     3              3\n",
      "11          4           4                     4              4\n",
      "71          3           3                     3              3\n",
      "76          3           3                     3              3\n",
      "..        ...         ...                   ...            ...\n",
      "302         4           4                     4              4\n",
      "303         6           6                     6              6\n",
      "304         8           8                     8              8\n",
      "305         2           2                     2              2\n",
      "307         2           2                     2              2\n",
      "\n",
      "[81 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for tool in tools_order:\n",
    "    print(tool)\n",
    "    csv = pd.read_csv('patterns-telatko-' + tool + '.csv')\n",
    "    \n",
    "    header = {\n",
    "        metrics[0]: [],\n",
    "        metrics[1] : [],\n",
    "        metrics[2] : [],\n",
    "        metrics[3] : [],\n",
    "    }\n",
    "    i = 0\n",
    "    for _,r in csv.iterrows():\n",
    "        \n",
    "        header[metrics[i]].append(r['output.acc_sets'])\n",
    "        i = (i + 1) % 4\n",
    "    data_dd = pd.DataFrame(data = header)\n",
    "    data_de = data_dd.dropna()\n",
    "    \n",
    "    data_df = data_de[(data_de['Original'] > 1)]\n",
    "    data[tool] = data_df\n",
    "    print(data_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>autcount</th>\n",
       "      <th>Original</th>\n",
       "      <th>Original%</th>\n",
       "      <th>Multilevel</th>\n",
       "      <th>Multilevel%</th>\n",
       "      <th>Autfilt -- simpl-acc</th>\n",
       "      <th>Autfilt -- simpl-acc%</th>\n",
       "      <th>Autfilt small</th>\n",
       "      <th>Autfilt small%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delag</td>\n",
       "      <td>129</td>\n",
       "      <td>523</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>379</td>\n",
       "      <td>27.5%</td>\n",
       "      <td>404</td>\n",
       "      <td>22.8%</td>\n",
       "      <td>398</td>\n",
       "      <td>23.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rabinizer4</td>\n",
       "      <td>234</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>541</td>\n",
       "      <td>38.7%</td>\n",
       "      <td>620</td>\n",
       "      <td>29.7%</td>\n",
       "      <td>621</td>\n",
       "      <td>29.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ltl2tgba</td>\n",
       "      <td>70</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>189</td>\n",
       "      <td>4.5%</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ltl3tela</td>\n",
       "      <td>91</td>\n",
       "      <td>348</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>323</td>\n",
       "      <td>7.2%</td>\n",
       "      <td>348</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>348</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltl3tela_det</td>\n",
       "      <td>81</td>\n",
       "      <td>272</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>272</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>272</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>272</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tool  autcount  Original Original%  Multilevel Multilevel%  \\\n",
       "0         delag       129       523      0.0%         379       27.5%   \n",
       "1    rabinizer4       234       882      0.0%         541       38.7%   \n",
       "2      ltl2tgba        70       198      0.0%         189        4.5%   \n",
       "3      ltl3tela        91       348      0.0%         323        7.2%   \n",
       "4  ltl3tela_det        81       272      0.0%         272        0.0%   \n",
       "\n",
       "   Autfilt -- simpl-acc Autfilt -- simpl-acc%  Autfilt small Autfilt small%  \n",
       "0                   404                 22.8%            398          23.9%  \n",
       "1                   620                 29.7%            621          29.6%  \n",
       "2                   198                  0.0%            198           0.0%  \n",
       "3                   348                  0.0%            348           0.0%  \n",
       "4                   272                  0.0%            272           0.0%  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdata = {\n",
    "    'tool': [],\n",
    "    'autcount': [],\n",
    "}\n",
    "for m in metrics:\n",
    "    sumdata[m] = []\n",
    "    sumdata[m + \"%\"] = []\n",
    "\n",
    "for tool in tools_order:\n",
    "    \n",
    "    data_df = data[tool]\n",
    "    \n",
    "    \n",
    "    sumdata['tool'].append(tool)\n",
    "    sd = data_df.sum()\n",
    "    sumdata['autcount'].append(len(data[tool]))\n",
    "    \n",
    "    for m in metrics:\n",
    "        sumdata[m].append(int(sd[m]))\n",
    "        sumdata[m + \"%\"].append(str(round(100 - (int(sd[m]) *100/int(sd['Original'])), 1)) + \"%\")\n",
    "        \n",
    "r = pd.DataFrame(data = sumdata)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-51a19aeb3601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m#for k in ht:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m#    print(tool, k, len(ht[k]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdata_dd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mdata_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L1.qbfr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L2.qbfr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L3.qbfr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L4.qbfr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L0.acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "llre = re.compile('^Running \\[A([1234])\\].*\\'(.*?)\\'$')\n",
    "hnre = re.compile('^name: \"(.*)\"$')\n",
    "nxre = re.compile('_([TU])\\\\s*$')\n",
    "\n",
    "for tool in tools_order:\n",
    "    csv = pd.read_csv('patterns-telatko-' + tool + '.csv')\n",
    "    log = 'autcross/' + tool + '.log'\n",
    "    \n",
    "    ht = {\n",
    "#        'aut_id': [],\n",
    "        'L0.acc': [],\n",
    "        'L1.acc': [],\n",
    "        'L1.time': [],\n",
    "        'L1.qbfr': [],\n",
    "        'L2.acc': [],\n",
    "        'L2.time': [],\n",
    "        'L2.qbfr': [],\n",
    "        'L3.acc': [],\n",
    "        'L3.time': [],\n",
    "        'L3.qbfr': [],\n",
    "        'L4.acc': [],\n",
    "        'L4.time': [],\n",
    "        'L4.qbfr': [],\n",
    "    }\n",
    "\n",
    "    #for (ix,_),_ in fs.iterrows():\n",
    "    #    ht['aut_id'].append(ix)\n",
    "\n",
    "    i = 0\n",
    "    for _,r in csv.iterrows():\n",
    "        ht['L' + str(i) + '.acc'].append(r['output.acc_sets'])\n",
    "        if i > 0:\n",
    "            ht['L' + str(i) + '.time'].append(r['time'])\n",
    "\n",
    "        i = (i + 1) % 5\n",
    "    \n",
    "    logfd = open(log, 'r')\n",
    "    for ll in logfd.readlines():\n",
    "        lmatch = llre.match(ll)\n",
    "        if lmatch:\n",
    "            level = lmatch.group(1)\n",
    "            hoa = lmatch.group(2)\n",
    "\n",
    "            hoafd = open(hoa, 'r')\n",
    "            aut_seen = False\n",
    "            name_seen = False\n",
    "            for hl in hoafd.readlines():\n",
    "                if len(hl) > 3:\n",
    "                    aut_seen = True\n",
    "                hmatch = hnre.match(hl)\n",
    "                if hmatch:\n",
    "                    name_seen = True\n",
    "                    xmatch = nxre.search(hmatch.group(1))\n",
    "                    if xmatch:\n",
    "                        ht['L' + level + '.qbfr'].append(xmatch.group(1))\n",
    "                    else:\n",
    "                        ht['L' + level + '.qbfr'].append('U')\n",
    "                    break\n",
    "\n",
    "            hoafd.close()\n",
    "\n",
    "            if not aut_seen:\n",
    "                ht['L' + level + '.qbfr'].append('X')\n",
    "            elif not name_seen:\n",
    "                ht['L' + level + '.qbfr'].append('U')\n",
    "\n",
    "    logfd.close()\n",
    "\n",
    "    #for k in ht:\n",
    "    #    print(tool, k, len(ht[k]))\n",
    "    data_dd = pd.DataFrame(data = ht)\n",
    "    data_de = data_dd.dropna()\n",
    "    data_df = data_de[(data_de['L1.qbfr'] != 'X') & (data_de['L2.qbfr'] != 'X') & (data_de['L3.qbfr'] != 'X') & (data_de['L4.qbfr'] != 'X') & (data_de['L0.acc'] > 1)]\n",
    "    data[tool] = data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdata = {\n",
    "    'tool': [],\n",
    "    'ltlcount': [],\n",
    "    'autcount': [],\n",
    "    'L0.acc': [],\n",
    "}\n",
    "for l in range(1, 7):\n",
    "    for s in ['acc', 'time', 'ratio', 'qbft', 'qbfu']:\n",
    "        sumdata['L' + str(l) + '.' + s] = []\n",
    "\n",
    "for tool in tools_order:\n",
    "    data_df = data[tool]\n",
    "    \n",
    "    sumdata['tool'].append(tool)\n",
    "    sd = data_df.sum()\n",
    "    sumdata['ltlcount'].append(ltlf_translated[tool])\n",
    "    sumdata['autcount'].append(len(data_df))\n",
    "    for i in range(0, 7):\n",
    "        sumdata['L' + str(i) + '.acc'].append(int(sd['L' + str(i) + '.acc']))\n",
    "        if i > 0:\n",
    "            t = sd['L' + str(i) + '.time']\n",
    "            #if i > 1 and i < 4:\n",
    "            #    t -= sd['L' + str(i - 1) + '.time']\n",
    "            sumdata['L' + str(i) + '.time'].append(round(t, 1))\n",
    "            sumdata['L' + str(i) + '.ratio'].append(\n",
    "                round(100 - 100 * int(sd['L' + str(i) + '.acc']) / int(sd['L0.acc']), 1)\n",
    "            )\n",
    "            \n",
    "            for x in ['T', 'U']:\n",
    "                sumdata['L' + str(i) + '.qbf' + x.lower()].append(len(data_df[data_df['L' + str(i) + '.qbfr'] == x]))\n",
    "\n",
    "#for k in sumdata:\n",
    "#    print(k, len(sumdata[k]))\n",
    "r = pd.DataFrame(data = sumdata)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
